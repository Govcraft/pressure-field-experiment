\documentclass[10pt,letterpaper]{article}

%% Page layout - NeurIPS style
\usepackage[margin=1in,left=1.5in,right=1.5in]{geometry}

%% Font - Computer Modern (matches Typst's "New Computer Modern")
\usepackage[T1]{fontenc}
\usepackage{lmodern}

%% Microtypographic optimization - reduces rivers in justified text
\usepackage[
  activate={true,nocompatibility},
  tracking=true,
  kerning=true,
  spacing=true,
  factor=1100,
  stretch=10,
  shrink=10
]{microtype}
\microtypecontext{spacing=nonfrench}

%% Packages
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xurl}
\usepackage{hyperref}
\hypersetup{breaklinks=true,colorlinks=true,linkcolor=black,citecolor=black,urlcolor=blue}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{titlesec}
\usepackage{parskip}
\usepackage{enumitem}
\usepackage{acro}

%% Acronym definitions
\DeclareAcronym{llm}{
  short = LLM,
  long  = Large Language Model
}
\DeclareAcronym{mas}{
  short = MAS,
  long  = Multi-Agent System
}
\DeclareAcronym{gpgp}{
  short = GPGP,
  long  = Generalized Partial Global Planning
}
\DeclareAcronym{fm}{
  short = FM,
  long  = Foundation Model
}
\DeclareAcronym{aco}{
  short = ACO,
  long  = Ant Colony Optimization
}
\DeclareAcronym{tsp}{
  short = TSP,
  long  = Traveling Salesman Problem
}
\DeclareAcronym{gpu}{
  short = GPU,
  long  = Graphics Processing Unit
}
\DeclareAcronym{ast}{
  short = AST,
  long  = Abstract Syntax Tree
}
\DeclareAcronym{sop}{
  short = SOP,
  long  = Standardized Operating Procedure
}
\DeclareAcronym{ci}{
  short = CI,
  long  = Confidence Interval
}

%% Paragraph formatting
\setlength{\parindent}{1.5em}
\setlength{\parskip}{0.5em}

%% Justification and hyphenation settings to reduce rivers
\tolerance=1000              % Allow moderate flexibility in word spacing
\emergencystretch=3em        % Additional stretch as last resort
\hyphenpenalty=50            % Encourage hyphenation to avoid large spaces
\exhyphenpenalty=50          % Same penalty for explicit hyphens

%% Section formatting - numbered, bold
\titleformat{\section}{\normalfont\fontsize{12}{14}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\fontsize{10}{12}\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalfont\fontsize{10}{12}\bfseries\itshape}{\thesubsubsection}{1em}{}
\titlespacing*{\section}{0pt}{1em}{0.5em}
\titlespacing*{\subsection}{0pt}{0.8em}{0.4em}
\titlespacing*{\subsubsection}{0pt}{0.6em}{0.3em}

%% Theorem environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

%% Custom algorithm environment
\newcounter{algorithm}
\newenvironment{algorithm}[1][]{%
  \refstepcounter{algorithm}%
  \begin{figure}[htbp]%
  \centering
  \begin{minipage}{0.95\textwidth}%
  \hrule\vspace{0.5em}%
  \noindent\textbf{Algorithm \thealgorithm}\ifx\\#1\\\else: \textbf{#1}\fi\par\vspace{0.5em}%
}{%
  \vspace{0.5em}\hrule%
  \end{minipage}%
  \end{figure}%
}

%% Code listing style
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  columns=fullflexible,
  keepspaces=true,
  showstringspaces=false,
  commentstyle=\color{gray},
  keywordstyle=\color{blue},
}

%% Custom abstract environment - centered, 85% width
\renewenvironment{abstract}{%
  \begin{center}
  \begin{minipage}{0.85\textwidth}
  \small
  \noindent\textbf{Abstract.}
}{%
  \end{minipage}
  \end{center}
  \vspace{1em}
}

%% Custom title/author formatting
\makeatletter
\renewcommand{\maketitle}{%
  \begin{center}
  \vspace*{0.5in}
  {\fontsize{16}{19}\bfseries\@title\par}
  \vspace{1em}
  {\normalsize\@author\par}
  \vspace{0.3em}
  {\normalsize January 2026\par}
  \vspace{1em}
  \end{center}
}
\makeatother

\begin{document}

\title{Emergent Coordination in Multi-Agent Systems\\via Pressure Fields and Temporal Decay\footnote{Code available at \url{https://github.com/Govcraft/schedule-experiment}}}

\author{Roland R. Rodriguez, Jr.\\[0.3em]
\small Independent Researcher\\
\small\textit{rrrodzilla@proton.me}}

\maketitle

\begin{abstract}
Current multi-agent \ac{llm} frameworks rely on explicit orchestration patterns borrowed from human organizational structures: planners delegate to executors, managers coordinate workers, and hierarchical control flow governs agent interactions. These approaches suffer from coordination overhead that scales poorly with agent count and task complexity. We propose a fundamentally different paradigm inspired by natural coordination mechanisms: agents operate locally on a shared artifact, guided only by pressure gradients derived from measurable quality signals, with temporal decay preventing premature convergence. We formalize this as optimization over a pressure landscape and prove convergence guarantees under mild conditions.

Empirically, on meeting room scheduling across 1350 trials, pressure-field coordination substantially outperforms all baselines: 48.5\% aggregate solve rate across all difficulty levels (86.7\% on easy problems) versus 12.6\% for conversation-based coordination, 1.5\% for hierarchical control, and 0.4\% for sequential and random baselines (all pairwise comparisons $p < 0.001$). Temporal decay is essential: disabling it reduces solve rate by 10 percentage points. On easy problems, pressure-field achieves 86.7\% solve rate compared to 37.8\% for the next-best baseline. The approach maintains consistent performance from 1 to 4 agents. Our key finding: implicit coordination through shared pressure gradients dramatically outperforms explicit hierarchical control. Foundation models enable this approach: their broad pretraining and zero-shot reasoning allow quality-improving patches from local pressure signals alone, without domain-specific coordination protocols. This suggests that constraint-driven emergence offers a simpler and more effective foundation for multi-agent AI.
\end{abstract}

\begin{center}
\begin{minipage}{0.85\textwidth}
\small\textbf{Keywords:} multi-agent systems, emergent coordination, decentralized optimization, \acs{llm} agents
\end{minipage}
\end{center}
\vspace{1em}

%% ============================================================================
%% INTRODUCTION
%% ============================================================================

\section{Introduction}

Multi-agent systems built on large language models have emerged as a promising approach to complex task automation~\cite{wu2023autogen,hong2023metagpt,li2023camel}. The dominant paradigm treats agents as organizational units: planners decompose tasks, managers delegate subtasks, and workers execute instructions under hierarchical supervision. This coordination overhead scales poorly with agent count and task complexity.

We demonstrate that \emph{implicit} coordination through shared state substantially outperforms explicit hierarchical control---without coordinators, planners, or message passing. Across 1350 trials on meeting room scheduling, pressure-field coordination achieves 48.5\% aggregate solve rate compared to 1.5\% for hierarchical control ($p < 0.001$, Cohen's $h = 1.97$ on easy problems). Conversation-based coordination (AutoGen-style) achieves 12.6\%, while sequential and random baselines achieve only 0.4\%.

Our approach draws inspiration from natural coordination mechanisms---ant colonies, immune systems, neural tissue---that coordinate through \emph{environment modification} rather than message passing. Agents observe local quality signals (pressure gradients), take locally-greedy actions, and coordination emerges from shared artifact state. The key insight is that \emph{local greedy decisions are effective for constraint satisfaction}: when problems exhibit locality (fixing one region rarely breaks distant regions), decentralized greedy optimization outperforms centralized planning. Temporal decay prevents premature convergence by ensuring continued exploration.

Our contributions:

\begin{enumerate}
\item We formalize \emph{pressure-field coordination} as a role-free, stigmergic alternative to organizational \ac{mas} paradigms. Unlike \ac{gpgp}'s hierarchical message-passing or SharedPlans' intention alignment, pressure-field achieves $O(1)$ coordination overhead through shared artifact state. Foundation models enable this approach: their broad pretraining allows quality-improving patches from local pressure signals without domain-specific coordination protocols.

\item We introduce \emph{temporal decay} as a mechanism for preventing premature convergence. Disabling decay reduces solve rate by 10 percentage points (from 96.7\% to 86.7\% in ablation studies), trapping agents in local minima.

\item We prove convergence guarantees for this coordination scheme under pressure alignment conditions.

\item We provide empirical evidence across 1350 trials showing: (a) pressure-field substantially outperforms hierarchical control (48.5\% vs 1.5\%), (b) all comparisons with baselines are highly significant ($p < 0.001$).
\end{enumerate}

%% ============================================================================
%% RELATED WORK
%% ============================================================================

\section{Related Work}

Our approach bridges four research traditions: multi-agent systems coordination theory provides the conceptual foundation; swarm intelligence provides the stigmergic mechanism; \ac{llm} systems provide the application domain; and decentralized optimization provides theoretical guarantees. We survey each and position pressure-field coordination within this landscape.

\subsection{\acs{mas} Coordination Theory}

Pressure-field coordination occupies a unique position in the \ac{mas} landscape: it eliminates roles (unlike organizational paradigms), messages (unlike \ac{gpgp}), and intention reasoning (unlike SharedPlans) while providing formal convergence guarantees (unlike purely reactive systems). This section positions our contribution within four established coordination frameworks, showing how artifact refinement with measurable quality signals enables this architectural simplification. The key insight: for this domain class, coordination complexity collapses from quadratic message-passing to constant-time state-sharing.

\subsubsection{Organizational Paradigms and Dependency Management}

Pressure-field coordination achieves role-free coordination: any agent can address any high-pressure region without negotiating access rights or awaiting task assignment. This contrasts sharply with traditional organizational paradigms. Horling and Lesser~\cite{horling2004survey} surveyed nine such paradigms---from rigid hierarchies to flexible markets---finding that all assign explicit roles constraining agent behavior. While role assignment reduces coordination complexity by pre-structuring interactions, it introduces brittleness: role changes require protocol modifications, and role failure can cascade through the system.

Our approach instantiates Malone and Crowston's~\cite{malone1994coordination} coordination framework with a critical difference: the artifact itself is the shared resource, and pressure gradients serve as dependency signals. Rather than assigning roles to manage resource access, agents share read access to the entire artifact and propose changes to high-pressure regions. Coordination emerges from pressure alignment---agents reduce local pressure, which reduces global pressure through the artifact's shared state.

\subsubsection{Distributed Problem Solving and Communication Overhead}

Pressure-field coordination achieves $O(1)$ inter-agent communication overhead---agents exchange no messages. Coordination occurs entirely through shared artifact reads and writes, eliminating the message-passing bottleneck. This contrasts with the \ac{gpgp} framework~\cite{decker1995gpgp}, which reduces communication from $O(n^2)$ pairwise negotiation to $O(n \log n)$ hierarchical aggregation through summary information exchange. While \ac{gpgp} represents significant progress, its explicit messages---task announcements, commitment exchanges, schedule updates---still introduce latency and failure points at scale.

The approaches target different domains. Pressure-field coordination specializes in artifact refinement tasks where quality decomposes into measurable regional signals---a class including code quality improvement, document editing, and configuration management. \Ac{gpgp} generalizes to complex task networks with precedence constraints. For artifact refinement, however, pressure-field's stigmergic coordination eliminates message-passing overhead entirely.

\subsubsection{Shared Intentions and Alignment Costs}

Pressure-field coordination eliminates intention alignment through pressure alignment. Rather than reasoning about what other agents believe or intend, agents observe artifact state and pressure gradients. When agents greedily reduce local pressure under separable or bounded-coupling conditions, global pressure decreases. This is coordination without communication about intentions---agents align through shared objective functions, not mutual beliefs.

This contrasts with the SharedPlans framework~\cite{grosz1996sharedplans}, which formalizes joint activity through shared mental attitudes: mutual beliefs about goals, commitments, and action sequences. The framework elegantly captures human-like collaboration but requires significant cognitive machinery---intention recognition, commitment protocols, belief revision---all computationally expensive operations that scale poorly with agent count.

Our experiments validate this analysis: pressure-field coordination eliminates the overhead of explicit dialogue by coordinating through shared artifact state. The coordination overhead of belief negotiation in explicit dialogue systems can exceed its organizational benefit for constraint satisfaction tasks. The trade-off is transparency: SharedPlans supports dialogue about why agents act; pressure-field agents react to gradients without explaining reasoning.

\subsubsection{Self-Organization and Emergent Coordination}

Pressure-field coordination satisfies De Wolf and Holvoet's~\cite{dewolf2005engineering} self-organization criteria: absence of external control, local interactions producing global patterns, and dynamic adaptation. They explicitly cite ``gradient fields'' as a self-organization design pattern---our approach instantiates this pattern with formal guarantees.

No external controller exists---agents observe and act autonomously based on local pressure signals. Coordination emerges from local decisions: agents reduce regional pressure through greedy actions, and global coordination arises from shared artifact state. Temporal decay provides dynamic adaptation---fitness erodes continuously, preventing premature convergence and enabling continued refinement.

The theoretical contribution formalizes this intuition through potential game theory. Theorem~1 establishes convergence guarantees for aligned pressure systems; the Basin Separation result (Theorem~3) explains why decay is necessary to escape suboptimal basins.

\subsubsection{Foundation Model Enablement}

\Acp{fm} enable stigmergic coordination through three capabilities: (1) broad pretraining allows patch proposals across diverse artifact types without domain-specific fine-tuning; (2) instruction-following allows operation from pressure signals alone, without complex action representations; (3) zero-shot reasoning interprets constraint violations without explicit protocol training. These properties make \acp{fm} suitable for stigmergic coordination---they require only local context and quality signals to generate productive actions, matching pressure-field's locality constraints.

\subsection{Multi-Agent \acs{llm} Systems}

Recent work has explored multi-agent architectures for \ac{llm}-based task solving. AutoGen~\cite{wu2023autogen} introduces a conversation-based framework where customizable agents interact through message passing, with support for human-in-the-loop workflows. MetaGPT~\cite{hong2023metagpt} encodes \acp{sop} into agent workflows, assigning specialized roles (architect, engineer, QA) in an assembly-line paradigm. CAMEL~\cite{li2023camel} proposes role-playing between AI assistant and AI user agents, using inception prompting to guide autonomous cooperation. CrewAI~\cite{crewai2024} similarly defines agents with roles, goals, and backstories that collaborate on complex tasks.

These frameworks share a common design pattern: explicit orchestration through message passing, role assignment, and hierarchical task decomposition. While effective for structured workflows, this approach faces scaling limitations. Central coordinators become bottlenecks, message-passing overhead grows with agent count, and failures in manager agents cascade to dependents. Our work takes a fundamentally different approach: coordination emerges from shared state rather than explicit communication.

Foundation models enable pressure-field coordination through capabilities that prior agent architectures lacked. Their broad pretraining allows reasonable patches across diverse artifact types---code, text, configurations---without domain-specific fine-tuning. Their instruction-following capabilities allow operation from pressure signals and quality feedback alone. Their zero-shot reasoning interprets constraint violations and proposes repairs without explicit protocol training. These properties make foundation models particularly suitable for stigmergic coordination: they require only local context and quality signals to generate productive actions, matching the locality constraints of pressure-field systems.

\subsection{Swarm Intelligence and Stigmergy}

The concept of stigmergy---indirect coordination through environment modification---was introduced by Grass\'{e}~\cite{grasse1959stigmergie} to explain termite nest-building behavior. Termites deposit pheromone-infused material that attracts further deposits, leading to emergent construction without central planning. This directly instantiates Malone and Crowston's~\cite{malone1994coordination} shared resource coordination: pheromone trails encode dependency information about solution quality. This principle has proven remarkably powerful: complex structures arise from simple local rules without any agent having global knowledge.

Dorigo and colleagues~\cite{dorigo1996ant,dorigo1997acs} formalized this insight into \ac{aco}, where artificial pheromone trails guide search through solution spaces. Key mechanisms include positive feedback (reinforcing good paths), negative feedback (pheromone evaporation), and purely local decision-making. \Ac{aco} has achieved strong results on combinatorial optimization problems including \ac{tsp}, vehicle routing, and scheduling.

Our pressure-field coordination directly inherits from stigmergic principles. The artifact serves as the shared environment; regional pressures are analogous to pheromone concentrations; decay corresponds to evaporation. However, we generalize beyond path-finding to arbitrary artifact refinement and provide formal convergence guarantees through the potential game framework.

\subsection{Decentralized Optimization}

Potential games, introduced by Monderer and Shapley~\cite{monderer1996potential}, are games where individual incentives align with a global potential function. A key property is that any sequence of unilateral improvements converges to a Nash equilibrium---greedy local play achieves global coordination. This provides the theoretical foundation for our convergence guarantees: under pressure alignment, the artifact pressure serves as a potential function.

Distributed gradient descent methods~\cite{nedic2009distributed,yuan2016convergence} address optimization when data or computation is distributed across nodes. The standard approach combines local gradient steps with consensus averaging. While these methods achieve convergence rates matching centralized alternatives, they typically require communication protocols and synchronization. Our approach avoids explicit communication entirely: agents coordinate only through the shared artifact, achieving $O(1)$ coordination overhead.

The connection between multi-agent learning and game theory has been extensively studied~\cite{shoham2008multiagent}. Our contribution is applying these insights to \ac{llm}-based artifact refinement, where the ``game'' is defined by pressure functions over quality signals rather than explicit reward structures.

%% ============================================================================
%% PROBLEM FORMULATION
%% ============================================================================

\section{Problem Formulation}

We formalize artifact refinement as a dynamical system over a pressure landscape rather than an optimization problem with a target state. The system evolves through local actions and continuous decay, settling into stable basins that represent acceptable artifact states.

\subsection{State Space}

An \emph{artifact} consists of $n$ regions with content $c_i \in \mathcal{C}$ for $i \in \{1, \ldots, n\}$, where $\mathcal{C}$ is an arbitrary content space (strings, \ac{ast} nodes, etc.). Each region also carries auxiliary state $h_i \in \mathcal{H}$ representing confidence, fitness, and history. Regions are passive subdivisions of the artifact; agents are active proposers that observe regions and generate patches.

The full system state is:
\[
s = ((c_1, h_1), \ldots, (c_n, h_n)) \in (\mathcal{C} \times \mathcal{H})^n
\]

\subsection{Pressure Landscape}

A \emph{signal function} $\sigma: \mathcal{C} \to \mathbb{R}^d$ maps content to measurable features. Signals are \emph{local}: $\sigma(c_i)$ depends only on region $i$.

A \emph{pressure function} $\phi: \mathbb{R}^d \to \mathbb{R}_{\geq 0}$ maps signals to scalar ``badness.'' We consider $k$ pressure axes with weights $\mathbf{w} \in \mathbb{R}^k_{>0}$. The \emph{region pressure} is:
\[
P_i(s) = \sum_{j=1}^k w_j \phi_j(\sigma(c_i))
\]

The \emph{artifact pressure} is:
\[
P(s) = \sum_{i=1}^n P_i(s)
\]

This defines a landscape over artifact states. Low-pressure regions are ``valleys'' where the artifact satisfies quality constraints.

\subsection{System Dynamics}

The system evolves in discrete time steps (ticks). Each tick consists of four phases:

\textbf{Phase 1: Decay.} Auxiliary state erodes toward a baseline. For fitness $f_i$ and confidence $\gamma_i$ components of $h_i$:
\[
f_i^{t+1} = f_i^t \cdot e^{-\lambda_f}, \quad \gamma_i^{t+1} = \gamma_i^t \cdot e^{-\lambda_\gamma}
\]
where $\lambda_f, \lambda_\gamma > 0$ are decay rates. Decay ensures that stability requires continuous reinforcement.

\textbf{Phase 2: Proposal.} For each region $i$ where pressure exceeds activation threshold ($P_i > \tau_{\text{act}}$) and the region is not inhibited, \emph{each actor} $a_k: \mathcal{C} \times \mathcal{H} \times \mathbb{R}^d \to \mathcal{C}$ proposes a content transformation in parallel. Each actor observes only local state $(c_i, h_i, \sigma(c_i))$---actors do not communicate or coordinate their proposals.

\textbf{Phase 3: Validation.} When multiple patches are proposed, each is validated on an independent \emph{fork} of the artifact. Forks are created by cloning artifact state; validation proceeds in parallel across forks. This addresses a fundamental resource constraint: a single artifact cannot be used to test multiple patches simultaneously without cloning.

\textbf{Phase 4: Reinforcement.} Regions where actions were applied receive fitness and confidence boosts, and enter an inhibition period preventing immediate re-modification. Inhibition allows changes to propagate through the artifact and forces agents to address other high-pressure regions, preventing oscillation around local fixes.
\[
f_i^{t+1} = \min(f_i^t + \Delta_f, 1), \quad \gamma_i^{t+1} = \min(\gamma_i^t + \Delta_\gamma, 1)
\]

\subsection{Stable Basins}

\begin{definition}[Stability]
A state $s^*$ is \emph{stable} if, under the system dynamics with no external perturbation:
\begin{enumerate}
\item All region pressures are below activation threshold: $P_i(s^*) < \tau_{\text{act}}$ for all $i$
\item Decay is balanced by residual fitness: the system remains in a neighborhood of $s^*$
\end{enumerate}
\end{definition}

The central questions are:
\begin{enumerate}
\item \textbf{Existence}: Under what conditions do stable basins exist?
\item \textbf{Quality}: What is the pressure $P(s^*)$ of states in stable basins?
\item \textbf{Convergence}: From initial state $s_0$, does the system reach a stable basin? How quickly?
\item \textbf{Decentralization}: Can stability be achieved with purely local decisions?
\end{enumerate}

\subsection{The Locality Constraint}

The key constraint distinguishing our setting from centralized optimization: agents observe only local state. An actor at region $i$ sees $(c_i, h_i, \sigma(c_i))$ but not:
\begin{itemize}
\item Other regions' content $c_j$ for $j \neq i$
\item Global pressure $P(s)$
\item Other agents' actions
\end{itemize}

This rules out coordinated planning. Stability must emerge from local incentives aligned with global pressure reduction.

%% ============================================================================
%% METHOD
%% ============================================================================

\section{Method}

We now present a coordination mechanism that achieves stability through purely local decisions. The key insight is that under appropriate conditions, the artifact pressure $P(s)$ acts as a \emph{potential function}: local improvements by individual agents decrease global pressure, guaranteeing convergence without coordination.

\subsection{Pressure Alignment}

The locality constraint prohibits agents from observing global state. For decentralized coordination to succeed, we need local incentives to align with global pressure reduction.

\begin{definition}[Pressure Alignment]
A pressure system is \emph{aligned} if for any region $i$, state $s$, and action $a_i$ that reduces local pressure:
\[
P_i(s') < P_i(s) \quad \Longrightarrow \quad P(s') < P(s)
\]
where $s' = s[c_i \mapsto a_i(c_i)]$ is the state after applying $a_i$.
\end{definition}

Alignment holds automatically when pressure functions are \emph{separable}: each $P_i$ depends only on $c_i$, so $P(s) = \sum_i P_i(s)$ and local improvement directly implies global improvement.

More generally, alignment holds when cross-region interactions are bounded:

\begin{definition}[Bounded Coupling]
A pressure system has \emph{$\epsilon$-bounded coupling} if for any action $a_i$ on region $i$:
\[
|P_j(s') - P_j(s)| \leq \epsilon \quad \forall j \neq i
\]
That is, modifying region $i$ changes other regions' pressures by at most $\epsilon$.
\end{definition}

Under $\epsilon$-bounded coupling with $n$ regions, if a local action reduces $P_i$ by $\delta > (n-1)\epsilon$, then global pressure decreases by at least $\delta - (n-1)\epsilon > 0$.

\subsection{Connection to Potential Games}

The aligned pressure system forms a \emph{potential game} where:
\begin{itemize}
\item Players are regions (or agents acting on regions)
\item Strategies are content choices $c_i \in \mathcal{C}$
\item The potential function is $\Phi(s) = P(s)$
\end{itemize}

In potential games, any sequence of improving moves converges to a Nash equilibrium. In our setting, Nash equilibria correspond to stable basins: states where no local action can reduce pressure below the activation threshold.

This connection provides our convergence guarantee without requiring explicit coordination.

Note that this convergence result assumes finite action spaces. In practice, patches are drawn from a finite set of \ac{llm}-generated proposals per region, satisfying this requirement. For infinite content spaces, convergence to approximate equilibria can be established under Lipschitz continuity conditions on pressure functions.

\subsection{The Coordination Algorithm}

The tick loop implements greedy local improvement with decay-driven exploration:

\begin{algorithm}[Pressure-Field Tick]
\textbf{Input:} State $s^t$, signal functions $\{\sigma_j\}$, pressure functions $\{\phi_j\}$, actors $\{a_k\}$, parameters $(\tau_{\text{act}}, \lambda_f, \lambda_\gamma, \Delta_f, \Delta_\gamma, \kappa)$

\textbf{Phase 1: Decay}\\
\hspace{1em} For each region $i$: $\quad f_i \gets f_i \cdot e^{-\lambda_f}, \quad \gamma_i \gets \gamma_i \cdot e^{-\lambda_\gamma}$

\textbf{Phase 2: Activation and Proposal}\\
\hspace{1em} $\mathcal{P} \gets \emptyset$\\
\hspace{1em} For each region $i$ where $P_i(s) \geq \tau_{\text{act}}$ and not inhibited:\\
\hspace{2em} $\boldsymbol{\sigma}_i \gets \sigma(c_i)$\\
\hspace{2em} For each actor $a_k$:\\
\hspace{3em} $\delta \gets a_k(c_i, h_i, \boldsymbol{\sigma}_i)$\\
\hspace{3em} $\mathcal{P} \gets \mathcal{P} \cup \{(i, \delta, \hat{\Delta}(\delta))\}$

\textbf{Phase 3: Parallel Validation and Selection}\\
\hspace{1em} For each candidate patch $(i, \delta, \hat{\Delta}) \in \mathcal{P}$:\\
\hspace{2em} Fork artifact: $(f_{\text{id}}, A_f) \gets A.\text{fork}()$\\
\hspace{2em} Apply $\delta$ to fork $A_f$\\
\hspace{2em} Validate fork (run tests, check compilation)\\
\hspace{1em} Collect validation results $\{(i, \delta, \Delta_{\text{actual}}, \text{valid})\}$\\
\hspace{1em} Sort validated patches by $\Delta_{\text{actual}}$\\
\hspace{1em} Greedily select top-$\kappa$ non-conflicting patches

\textbf{Phase 4: Application and Reinforcement}\\
\hspace{1em} For each selected patch $(i, \delta, \cdot)$:\\
\hspace{2em} $c_i \gets \delta(c_i)$\\
\hspace{2em} $f_i \gets \min(f_i + \Delta_f, 1)$, $\gamma_i \gets \min(\gamma_i + \Delta_\gamma, 1)$\\
\hspace{2em} Mark region $i$ inhibited for $\tau_{\text{inh}}$ ticks

\textbf{Return} updated state $s^{t+1}$
\end{algorithm}

The algorithm has three key properties:

\textbf{Locality.} Each actor observes only $(c_i, h_i, \sigma(c_i))$. No global state is accessed.

\textbf{Bounded parallelism.} At most $\kappa$ patches per tick prevents thrashing. Inhibition prevents repeated modification of the same region.

\textbf{Decay-driven exploration.} Even stable regions eventually decay below confidence thresholds, attracting re-evaluation. This prevents premature convergence to local minima.

\subsection{Stability and Termination}

The system reaches a stable basin when:
\begin{enumerate}
\item All region pressures satisfy $P_i(s) < \tau_{\text{act}}$
\item Decay is balanced: fitness remains above the threshold needed for stability
\end{enumerate}

Termination is \emph{economic}, not logical. The system stops acting when the cost of action (measured in pressure reduction per patch) falls below the benefit. This matches natural systems: activity ceases when gradients flatten, not when an external goal is declared achieved.

In practice, we also impose budget constraints (maximum ticks or patches) to bound computation.

%% ============================================================================
%% THEORETICAL ANALYSIS
%% ============================================================================

\section{Theoretical Analysis}

We establish three main results: (1) convergence to stable basins under alignment, (2) bounds on stable basin quality, and (3) scaling properties relative to centralized alternatives.

\subsection{Convergence Under Alignment}

\begin{theorem}[Convergence]
Let the pressure system be aligned with $\epsilon$-bounded coupling. Let $\delta_{\min} > 0$ be the minimum \emph{local} pressure reduction $P_i(s) - P_i(s')$ from any applied patch, and assume $\delta_{\min} > (n-1)\epsilon$ where $n$ is the number of regions. Then from any initial state $s_0$ with pressure $P_0 = P(s_0)$, the system reaches a stable basin within:
\[
T \leq \frac{P_0}{\delta_{\min} - (n-1)\epsilon}
\]
ticks, provided the fitness boost $\Delta_f$ from successful patches exceeds decay during inhibition: $\Delta_f > 1 - e^{-\lambda_f \cdot \tau_{\text{inh}}}$.
\end{theorem}

\emph{Proof sketch.} Under alignment with $\epsilon$-bounded coupling, each applied patch reduces global pressure by at least $\delta_{\min} - (n-1)\epsilon > 0$. Since $P(s) \geq 0$ and decreases by a fixed minimum per tick (when patches are applied), the system must reach a state where no region exceeds $\tau_{\text{act}}$ within the stated bound. The decay constraint ensures that stability is maintained once reached: fitness reinforcement from the final patches persists longer than the decay erodes it. $\square$

The bound is loose but establishes the key property: convergence time scales with initial pressure, not with state space size or number of possible actions.

\subsection{Basin Quality}

\begin{theorem}[Basin Quality]
In any stable basin $s^*$, the artifact pressure satisfies:
\[
P(s^*) < n \cdot \tau_{\text{act}}
\]
where $n$ is the number of regions and $\tau_{\text{act}}$ is the activation threshold.
\end{theorem}

\emph{Proof.} By definition of stability, $P_i(s^*) < \tau_{\text{act}}$ for all $i$. Summing over regions: $P(s^*) = \sum_i P_i(s^*) < n \cdot \tau_{\text{act}}$. $\square$

This bound is tight: adversarial initial conditions can place the system in a basin where each region has pressure just below threshold. However, in practice, actors typically reduce pressure well below $\tau_{\text{act}}$, yielding much lower basin pressures.

\begin{theorem}[Basin Separation]
Under separable pressure (zero coupling), distinct stable basins are separated by pressure barriers of height at least $\tau_{\text{act}}$.
\end{theorem}

\emph{Proof sketch.} Moving from one basin to another requires some region to exceed $\tau_{\text{act}}$ (otherwise no action is triggered). The minimum such exceedance defines the barrier height. $\square$

This explains why decay is necessary: without decay, the system can become trapped in suboptimal basins. Decay gradually erodes fitness, eventually allowing re-evaluation and potential escape to lower-pressure basins.

\subsection{Scaling Properties}

\begin{theorem}[Linear Scaling]
Let $m$ be the number of regions and $n$ be the number of parallel agents. The per-tick complexity is:
\begin{itemize}
\item \textbf{Signal computation:} $O(m \cdot d)$ where $d$ is signal dimension
\item \textbf{Pressure computation:} $O(m \cdot k)$ where $k$ is the number of pressure axes
\item \textbf{Patch proposal:} $O(m \cdot a)$ where $a$ is the number of actors
\item \textbf{Selection:} $O(m \cdot a \cdot \log(m \cdot a))$ for sorting candidates
\item \textbf{Coordination overhead:} $O(1)$---no inter-agent communication (fork pool is $O(K)$ where $K$ is fixed)
\end{itemize}
Total: $O(m \cdot (d + k + a \cdot \log(ma)))$, independent of agent count $n$.
\end{theorem}

The key observation: adding agents increases throughput (more patches proposed per tick) without increasing coordination cost. This contrasts with hierarchical schemes where coordination overhead grows with agent count.

\begin{theorem}[Parallel Convergence]
Under the same alignment conditions as Theorem~1, with $K$ patches validated in parallel per tick where patches affect disjoint regions, the system reaches a stable basin within:
\[
T \leq \frac{P_0}{K \cdot (\delta_{\min} - (n-1)\epsilon)}
\]
This improves convergence time by factor $K$ while maintaining guarantees.
\end{theorem}

\emph{Proof sketch.} When $K$ non-conflicting patches are applied per tick, each reduces global pressure by at least $\delta_{\min} - (n-1)\epsilon$. The combined reduction is $K \cdot (\delta_{\min} - (n-1)\epsilon)$ per tick. The bound follows directly. Note that if patches conflict (target the same region), only one is selected per region, and effective speedup is reduced. $\square$

\subsection{Comparison to Alternatives}

We compare against three coordination paradigms:

\textbf{Centralized planning.} A global planner evaluates all $(m \cdot a)$ possible actions, selects optimal subset. Per-step complexity: $O(m \cdot a)$ evaluations, but requires global state access. Sequential bottleneck prevents parallelization.

\textbf{Hierarchical delegation.} Manager agents decompose tasks, delegate to workers. Communication complexity: $O(n \log n)$ for tree-structured delegation with $n$ agents. Latency scales with tree depth. Failure of manager blocks all descendants.

\textbf{Message-passing coordination.} Agents negotiate actions through pairwise communication. Convergence requires $O(n^2)$ messages in worst case for $n$ agents. Consensus protocols add latency.

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Paradigm} & \textbf{Coordination} & \textbf{Parallelism} & \textbf{Fault tolerance} \\
\midrule
Centralized & $O(m \cdot a)$ & None & Single point of failure \\
Hierarchical & $O(n \log n)$ & Limited by tree & Manager failure cascades \\
Message-passing & $O(n^2)$ & Consensus-bound & Partition-sensitive \\
Pressure-field & $O(1)$ & Full ($\min(n, m, K)$) & Graceful degradation \\
\bottomrule
\end{tabular}
\caption{Coordination overhead comparison. $K$ denotes the fork pool size for parallel validation.}
\label{tab:coordination}
\end{table}

Pressure-field coordination achieves $O(1)$ coordination overhead because agents share state only through the artifact itself---a form of stigmergy. Agents can fail, join, or leave without protocol overhead.

%% ============================================================================
%% EXPERIMENTS
%% ============================================================================

\section{Experiments}

We evaluate pressure-field coordination on meeting room scheduling: assigning $N$ meetings to $R$ rooms over $D$ days to minimize gaps (unscheduled time), overlaps (attendee double-bookings), and maximize utilization balance. This domain provides continuous pressure gradients (rather than discrete violations), measurable success criteria, and scalable difficulty through problem size.

\textbf{Key findings}: Pressure-field coordination substantially outperforms all baselines (\S5.2). Temporal decay is critical---disabling it reduces solve rate by 10 percentage points (\S5.3). The approach maintains consistent performance from 1 to 4 agents (\S5.4).

\subsection{Setup}

\subsubsection{Task: Meeting Room Scheduling}

We generate scheduling problems with varying difficulty:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Difficulty} & \textbf{Rooms} & \textbf{Meetings} & \textbf{Pre-scheduled} \\
\midrule
Easy & 3 & 20 & 70\% \\
Medium & 5 & 40 & 50\% \\
Hard & 5 & 60 & 30\% \\
\bottomrule
\end{tabular}
\caption{Problem configurations. Pre-scheduled percentage indicates meetings already placed; remaining must be scheduled by agents.}
\label{tab:problems}
\end{table}

Each schedule spans 5 days with 30-minute time slots (8am--4pm). Regions are 2-hour time blocks (20 regions per schedule). A problem is ``solved'' when all meetings are scheduled with zero attendee overlaps within 50 ticks.

\textbf{Pressure function}: $P = \text{gaps} \cdot 1.0 + \text{overlaps} \cdot 2.0 + \text{util\_var} \cdot 0.5 + \text{unsched} \cdot 1.5$

where $\text{gaps}$ measures empty slots as a fraction, $\text{overlaps}$ counts attendee double-bookings, $\text{util\_var}$ measures room utilization variance, and $\text{unsched}$ is the fraction of unscheduled meetings.

\subsubsection{Baselines}

We compare five coordination strategies, all using identical \acp{llm} (\texttt{qwen2.5:0.5b/1.5b/3b} via Ollama) to isolate coordination effects:

\textbf{Pressure-field (ours)}: Full system with decay (fitness half-life 5s), inhibition (2s cooldown), greedy region selection (highest-pressure region per tick), and parallel validation. Includes band escalation (Exploitation $\to$ Balanced $\to$ Exploration) and model escalation (0.5b $\to$ 1.5b $\to$ 3b).

\textbf{Conversation}: AutoGen-style multi-agent dialogue where agents exchange messages to coordinate scheduling decisions. Agents discuss conflicts and propose solutions through explicit communication.

\textbf{Hierarchical}: Single agent selects the highest-pressure time block each tick, proposes a schedule change, and validates before applying (only accepts pressure-reducing patches). Uses identical prompts to pressure-field. The key differences are: (1) greedy region selection always targets the hardest region, and (2) sequential execution processes one region per tick. This represents centralized, quality-gated control.

\textbf{Sequential}: Single agent iterates through time blocks in fixed order, proposing schedule changes one region at a time. No parallelism, pressure guidance, or patch validation---applies any syntactically valid patch regardless of quality impact.

\textbf{Random}: Selects random time blocks and proposes schedule changes. No patch validation---applies any syntactically valid patch regardless of quality impact.

\textbf{Note on parallelism}: Pressure-field validates multiple patches in parallel ($K$ regions per tick), while hierarchical validates one patch sequentially. This asymmetry is \emph{inherent to the coordination paradigm}, not an implementation choice: hierarchical control requires the manager to select a region, delegate to a worker, and validate the result before proceeding---delegating to multiple workers simultaneously would require additional coordination protocols (work distribution, conflict resolution, result aggregation) that would transform it into a different architecture entirely. The sequential bottleneck is the cost of centralized control. When hierarchical's single patch is rejected, the tick produces no progress; when one of pressure-field's parallel patches is rejected, others may still succeed.

\textbf{Model choice rationale}: We deliberately use small, minimally-capable models (0.5b--3b parameters) rather than frontier models. This design choice strengthens our thesis: if the coordination mechanism can extract effective performance from weak models, the mechanism itself is valuable---independent of model capability. Using identical model chains across all strategies isolates coordination effects from model effects.

\subsubsection{Metrics}

\begin{itemize}
\item \textbf{Solve rate}: Percentage of schedules reaching all meetings placed with zero overlaps within 50 ticks.
\item \textbf{Ticks to solve}: Convergence speed for solved cases
\item \textbf{Final pressure}: Remaining gaps, overlaps, and unscheduled meetings for unsolved cases
\end{itemize}

\subsubsection{Implementation}

\textbf{Hardware}: NVIDIA RTX 4070 8GB \ac{gpu}, AMD Ryzen 9 7940HS, 64GB RAM. \textbf{Software}: Rust implementation with Ollama. \textbf{Trials}: 30 per configuration. Full protocol in Appendix~A.

\textbf{Band escalation}: When pressure velocity (rate of improvement) drops to zero for 7 consecutive ticks, sampling parameters escalate: Exploitation (T=0.2, p=0.85) $\to$ Balanced (T=0.4, p=0.9) $\to$ Exploration (T=0.7, p=0.95).

\textbf{Model escalation}: After exhausting all bands with zero progress (21 ticks total), the system escalates through the model chain: 0.5b $\to$ 1.5b $\to$ 3b, resetting to Exploitation band. Section~\ref{sec:escalation} analyzes this mechanism.

\subsection{Main Results}

Across 1350 total trials spanning three difficulty levels (easy, medium, hard) and agent counts (1, 2, 4), we find that pressure-field coordination substantially outperforms all baselines:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Strategy} & \textbf{Solved/N} & \textbf{Rate} & \textbf{95\% Wilson \acs{ci}} \\
\midrule
Pressure-field & 131/270 & 48.5\% & 42.6\%--54.5\% \\
Conversation & 34/270 & 12.6\% & 9.2\%--17.1\% \\
Hierarchical & 4/270 & 1.5\% & 0.6\%--3.7\% \\
Sequential & 1/270 & 0.4\% & 0.1\%--2.1\% \\
Random & 1/270 & 0.4\% & 0.1\%--2.1\% \\
\bottomrule
\end{tabular}
\caption{Aggregate solve rates across all experiments (1350 total trials, 270 per strategy). Chi-square test across all five strategies: $\chi^2 > 200$, $p < 0.001$.}
\label{tab:main-results}
\end{table}

The key finding is \emph{dramatic stratification}:

\textbf{Pressure-field dominates}: Pressure-field achieves 48.5\% solve rate, nearly 4$\times$ higher than the next-best baseline (conversation at 12.6\%). The effect size is large: Cohen's $h = 1.07$ versus conversation on easy problems, and $h > 1.97$ versus all other baselines.

\textbf{Conversation provides intermediate performance}: The AutoGen-style conversation baseline achieves 12.6\% overall, significantly better than hierarchical ($p < 0.001$) but far below pressure-field. Notably, conversation solves only easy problems (37.8\% on easy, 0\% on medium and hard).

\textbf{Hierarchical and sequential fail}: Despite explicit coordination, hierarchical control achieves only 1.5\% solve rate---comparable to random (0.4\%). Both strategies fail entirely on medium and hard problems.

This result contradicts the common assumption that explicit hierarchical coordination should outperform implicit coordination. The overhead of centralized control and message passing appears to harm rather than help performance on constraint satisfaction tasks.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig1_strategy_comparison.pdf}
\caption{Strategy comparison by difficulty level. Error bars show 95\% Wilson \acp{ci}. Pressure-field substantially outperforms all baselines at every difficulty level. On medium and hard problems, only pressure-field achieves non-zero solve rates.}
\label{fig:strategy-comparison}
\end{figure}

\subsection{Ablations}

\subsubsection{Effect of Temporal Decay}

Decay proves essential---without it, solve rate decreases substantially:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Configuration} & \textbf{Solved/N} & \textbf{Solve Rate} & \textbf{95\% \acs{ci}} \\
\midrule
Full (with decay) & 29/30 & 96.7\% & 83.3\%--99.4\% \\
Without decay & 26/30 & 86.7\% & 70.3\%--94.7\% \\
\bottomrule
\end{tabular}
\caption{Decay ablation on easy scheduling problems (30 trials each). Disabling decay reduces solve rate by 10 percentage points.}
\label{tab:decay-ablation}
\end{table}

The effect is meaningful: disabling decay reduces solve rate from 96.7\% to 86.7\%. Without decay, fitness saturates after initial patches---regions that received early patches retain high fitness indefinitely, making them appear ``stable'' even when they still contain unscheduled meetings. Since greedy selection prioritizes high-pressure regions, these prematurely-stabilized regions are never reconsidered. This validates our theoretical analysis: Theorem~3 establishes that stable basins are separated by pressure barriers, and decay is necessary to escape these barriers and discover lower-pressure basins.

\subsubsection{Effect of Inhibition and Examples}

The ablation study tested combinations of decay, inhibition, and few-shot examples on easy scheduling problems:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Configuration} & \textbf{Decay} & \textbf{Inhib} & \textbf{Examples} & \textbf{Solve Rate} \\
\midrule
Full & \checkmark & \checkmark & \checkmark & 96.7\% \\
No Decay & $\times$ & \checkmark & \checkmark & 86.7\% \\
No Inhibition & \checkmark & $\times$ & \checkmark & 96.7\% \\
No Examples & \checkmark & \checkmark & $\times$ & 90.0\% \\
Baseline & $\times$ & $\times$ & $\times$ & 90.0\% \\
\bottomrule
\end{tabular}
\caption{Ablation results (30 trials each configuration on easy difficulty).}
\label{tab:ablation}
\end{table}

Feature contributions:
\begin{itemize}
\item \textbf{Decay}: +10.0\% (full 96.7\% vs no\_decay 86.7\%)
\item \textbf{Inhibition}: +0.0\% (no detectable effect)
\item \textbf{Examples}: +6.7\% (full 96.7\% vs no\_examples 90.0\%)
\end{itemize}

The key finding is that \emph{decay dominates}: configurations with decay achieve higher solve rates. Inhibition shows no detectable effect in this domain, possibly because the 50-tick budget provides sufficient exploration without explicit cooldowns.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{fig2_ablation.pdf}
\caption{Ablation study results. Left: feature matrix showing which components are enabled. Right: solve rates for each configuration. Decay provides the largest contribution (+10\%), followed by examples (+6.7\%). Inhibition shows no detectable effect.}
\label{fig:ablation}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{fig5_contributions.pdf}
\caption{Individual feature contributions to solve rate. Decay contributes +10.0\%, examples contribute +6.7\%, and inhibition shows no measurable effect in this domain.}
\label{fig:contributions}
\end{figure}

\subsubsection{Negative Pheromones}

In addition to positive pheromones (successful patches stored for few-shot examples), we implement \emph{negative pheromones}: tracking rejected patches that worsened pressure. When agents repeatedly propose ineffective patches (pressure stuck at maximum), the system accumulates rejection history and injects guidance into subsequent prompts.

Unlike the ``AVOID'' framing that small models (1.5B parameters) struggle to follow, we use \emph{positive language}: rejected empty-room patches become ``TIP: Schedule meetings in Room A (improves by X).'' This reframes what \emph{not} to do as what \emph{to try instead}.

Negative pheromones decay at the same rate as positive examples ($\text{weight} \times 0.95$ per tick, evicted below 0.1), ensuring that old failures don't permanently block valid approaches. Up to 3 recent rejections per region are included in prompts as ``Hints for better scheduling.''

\subsection{Scaling Experiments}

Pressure-field maintains consistent performance from 1 to 4 agents on easy difficulty:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Agents} & \textbf{Solved/N} & \textbf{Rate} & \textbf{95\% \acs{ci}} \\
\midrule
1 & 25/30 & 83.3\% & 66.4\%--92.7\% \\
2 & 28/30 & 93.3\% & 78.7\%--98.2\% \\
4 & 25/30 & 83.3\% & 66.4\%--92.7\% \\
\bottomrule
\end{tabular}
\caption{Pressure-field scaling from 1 to 4 agents (easy difficulty, 30 trials each). Performance remains stable across agent counts.}
\label{tab:scaling}
\end{table}

The key observation is \emph{robustness}: pressure-field coordination maintains consistent solve rates despite 4$\times$ variation in agent count. This validates Theorem~4: coordination overhead remains $O(1)$, enabling effective scaling. The slight peak at 2 agents (93.3\%) is within \ac{ci} overlap of 1 and 4 agents, indicating no significant agent-count effect.

\subsection{Band and Model Escalation}
\label{sec:escalation}

Ant colonies balance exploitation of known food sources against exploration for new ones. When a pheromone trail grows stale---indicating a depleted source---foragers abandon trail-following and resume random exploration, eventually discovering new paths that become the next generation of trails. This exploitation-exploration balance is fundamental to stigmergic systems: premature commitment to suboptimal solutions must be counteracted by mechanisms that restore exploratory behavior.

Our escalation mechanism implements this principle through two complementary dynamics. \emph{Band escalation} governs the exploitation-exploration trade-off within a single model: when pressure velocity drops to zero (the ``trail goes cold''), sampling parameters shift from exploitation (low temperature, focused proposals) through balanced to exploration (high temperature, diverse proposals). This mirrors the ant's behavioral switch from trail-following to random wandering when pheromone signals weaken.

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Band} & \textbf{Temperature} & \textbf{Top-p} \\
\midrule
Exploitation & 0.15--0.35 & 0.80--0.90 \\
Balanced & 0.35--0.55 & 0.85--0.95 \\
Exploration & 0.55--0.85 & 0.90--0.98 \\
\bottomrule
\end{tabular}
\caption{Sampling parameter ranges per band. Temperature and top-p are randomly sampled within range for diversity. Escalation proceeds Exploitation $\to$ Balanced $\to$ Exploration as pressure velocity stalls.}
\label{tab:bands}
\end{table}

\emph{Model escalation} addresses a different failure mode: when exploration within a model's capability envelope fails to discover productive paths, the system recruits more capable agents. This mirrors the immune system's escalation from innate to adaptive response: macrophages and neutrophils handle routine pathogens quickly and cheaply, but when these first responders fail to clear an infection, the system escalates to T-cells and antibody-producing B-cells---slower to mobilize but capable of addressing threats invisible to simpler mechanisms. Similarly, model escalation (0.5b $\to$ 1.5b $\to$ 3b) reserves greater reasoning capacity for regions that resist simpler approaches. Each model upgrade resets to exploitation band, giving the more capable model opportunity to exploit solutions invisible to its predecessor before resorting to exploration.

This two-level mechanism---behavioral adaptation within agents (band escalation) and capability escalation across agents (model escalation)---maintains the stigmergic principle: coordination emerges from environment signals (pressure gradients) rather than explicit planning. The system does not ``decide'' to explore or escalate; it reacts to pressure stagnation, just as ants react to pheromone decay.

\subsection{Difficulty Scaling}

Performance varies substantially across difficulty levels, revealing the unique strength of pressure-field coordination:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Difficulty} & \textbf{Pressure-field} & \textbf{Conversation} & \textbf{Hierarchical} & \textbf{Sequential/Random} \\
\midrule
Easy & 86.7\% (78/90) & 37.8\% (34/90) & 4.4\% (4/90) & 1.1\% (1/90) \\
Medium & 43.3\% (39/90) & 0.0\% (0/90) & 0.0\% (0/90) & 0.0\% (0/90) \\
Hard & 15.6\% (14/90) & 0.0\% (0/90) & 0.0\% (0/90) & 0.0\% (0/90) \\
\midrule
\textbf{Total} & \textbf{48.5\%} (131/270) & \textbf{12.6\%} (34/270) & \textbf{1.5\%} (4/270) & \textbf{0.4\%} (1/270) \\
\bottomrule
\end{tabular}
\caption{Solve rate by difficulty level (90 trials each per difficulty, 270 per strategy total). Only pressure-field solves medium and hard problems. See Table~\ref{tab:main-results} for confidence intervals.}
\label{tab:difficulty}
\end{table}

The difficulty scaling reveals critical insights:

\begin{enumerate}
\item \textbf{Pressure-field is the only strategy that scales}: While all strategies degrade on harder problems, pressure-field maintains meaningful solve rates (43.3\% medium, 15.6\% hard) where all baselines achieve 0\%.

\item \textbf{The gap widens with difficulty}: On easy problems, pressure-field leads by 48.9 percentage points over conversation (86.7\% vs 37.8\%). On medium and hard problems, the gap becomes absolute---pressure-field solves problems that no baseline can solve.

\item \textbf{Effect sizes are large}: Cohen's $h$ on easy problems: $h = 1.07$ vs conversation, $h = 1.97$ vs hierarchical, $h = 2.18$ vs sequential/random.
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig3_effect_sizes.pdf}
\caption{Effect sizes (Cohen's $h$) for pressure-field versus each baseline on easy problems. The dashed line indicates the ``large effect'' threshold ($h = 0.8$). All comparisons exceed this threshold, with effects ranging from $h = 1.07$ (vs conversation) to $h = 2.18$ (vs sequential/random).}
\label{fig:effect-sizes}
\end{figure}

\subsection{Convergence Speed}

For solved cases, pressure-field converges faster than baselines on easy problems and maintains consistent convergence speed across difficulty levels:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Strategy} & \textbf{Easy} & \textbf{Medium} & \textbf{Hard} \\
\midrule
Pressure-field & 17.8 (n=78) & 34.6 (n=39) & 32.3 (n=14) \\
Conversation & 29.9 (n=34) & --- & --- \\
Hierarchical & 40.0 (n=4) & --- & --- \\
\bottomrule
\end{tabular}
\caption{Average ticks to solution by difficulty (solved cases only). Only pressure-field solves medium and hard problems. Dashes indicate no solved cases.}
\label{tab:convergence}
\end{table}

On easy problems, pressure-field solves 1.7$\times$ faster than conversation and 2.2$\times$ faster than hierarchical. Notably, pressure-field's convergence speed on hard problems (32.3 ticks) is comparable to medium problems (34.6 ticks)---the hard problems that \emph{do} get solved converge at similar rates, suggesting that solvability rather than convergence speed is the limiting factor on difficult problems.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.65\textwidth]{fig4_efficiency.pdf}
\caption{Mean ticks to solution on easy problems (solved cases only). Error bars show standard error. Pressure-field converges fastest (17.8 ticks), followed by conversation (29.9 ticks) and hierarchical (40.0 ticks).}
\label{fig:efficiency}
\end{figure}

\subsection{Final Pressure Analysis}

For both solved and unsolved cases, final pressure reveals solution quality:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Strategy} & \textbf{Easy} & \textbf{Medium} & \textbf{Hard} \\
\midrule
Pressure-field & 0.13 & 1.02 & 2.48 \\
Conversation & 26.3 & 58.2 & 90.1 \\
Hierarchical & 28.6 & 59.4 & 88.0 \\
\bottomrule
\end{tabular}
\caption{Average final pressure by difficulty (lower is better).}
\label{tab:final-pressure}
\end{table}

Pressure-field achieves dramatically lower final pressure: 200$\times$ lower on easy, 57$\times$ lower on medium, and 35$\times$ lower on hard problems compared to conversation and hierarchical baselines. Even when pressure-field does not fully solve a problem, it achieves much better partial solutions.

%% ============================================================================
%% DISCUSSION
%% ============================================================================

\section{Discussion}

\subsection{Why Does Pressure-Field Dominate?}

Our results contradict the intuition that explicit coordination should outperform implicit coordination. We identify three factors explaining pressure-field's dominance:

\textbf{Coordination overhead harms performance.} Hierarchical systems spend computational budget on coordination rather than problem-solving. The manager-worker protocol requires multiple \ac{llm} calls per patch (planning, delegation, execution), while pressure-field requires only one (patch proposal). This overhead compounds: hierarchical attempts fewer patches per tick, reducing exploration.

\textbf{Local greedy decisions are effective for constraint satisfaction.} Meeting room scheduling exhibits locality: fixing a conflict in one time block rarely creates conflicts in distant blocks. This matches pressure-field's locality assumption, making greedy local optimization effective. Hierarchical coordination's global planning provides no benefit for locally-decomposable problems.

\textbf{Parallel validation amplifies pressure-field's advantage.} Pressure-field validates patches for multiple regions simultaneously, applying the highest-scoring patch per region that reduces pressure. Hierarchical validates one patch at a time, requiring multiple ticks to explore alternatives. On problems with many valid solutions, parallel exploration finds solutions faster.

\subsection{Failure Analysis: Why Hierarchical Collapses}

The 30$\times$ performance gap (48.5\% vs 1.5\%) demands deeper investigation. Analysis of hierarchical trials reveals a catastrophic failure pattern: the \emph{rejection loop}.

\textbf{The rejection loop mechanism.} Hierarchical always selects the highest-pressure region for improvement. But the highest-pressure regions are high-pressure precisely because they are difficult to improve. When the \ac{llm} proposes a patch that fails validation (does not reduce pressure), the region remains highest-pressure and is selected again next tick. This creates a self-reinforcing cycle: 66.7\% of hierarchical runs (180/270) applied zero patches across all 50 ticks, stuck targeting the same intractable region repeatedly.

\textbf{Rejection rates confirm the pattern.} Across all hierarchical trials, only 173 patches were accepted out of 13,460 proposed---a 98.7\% rejection rate. By contrast, pressure-field's parallel exploration means that even if one agent's patch is rejected, other agents make progress on different regions. The non-blocking architecture prevents any single difficult region from stalling the entire system.

\textbf{The architectural lesson.} Hierarchical's design embodies a reasonable intuition: focus intelligent effort on the worst problems. But this creates a trap when combined with strict validation: the hardest problems resist improvement, causing repeated rejection, which blocks progress everywhere. Pressure-field avoids this trap through distributed exploration---progress happens where it can, not where a central planner dictates it must.

\subsection{Limitations}

Our experiments reveal several important limitations:

\textbf{Absolute solve rates are modest on hard problems.} Even pressure-field achieves only 15.6\% on hard problems. Meeting room scheduling with tight constraints (5 rooms, 60 meetings, 30\% pre-scheduled) remains challenging for small models (0.5b--3b parameters); larger models may achieve higher absolute solve rates.

\textbf{Domain specificity.} Results on meeting room scheduling may not generalize to domains lacking measurable pressure gradients or locality properties. Tasks requiring global planning or long-horizon reasoning may favor hierarchical approaches.

\textbf{Additional practical limitations:}
\begin{itemize}
\item Requires well-designed pressure functions (not learned from data)
\item Decay rates $\lambda_f, \lambda_\gamma$ and inhibition period require task-specific tuning
\item May not suit tasks requiring long-horizon global planning
\item Goodhart's Law: agents may game poorly-designed metrics
\item Resource cost of parallel validation: testing $K$ patches requires $O(K \cdot |A|)$ memory where $|A|$ is artifact size
\end{itemize}

\subsection{When to Choose Each Approach}

Our results suggest the following guidance:

\textbf{Pressure-field coordination is preferable when:}
\begin{enumerate}
\item \textbf{Performance matters.} Pressure-field achieves 3--30$\times$ higher solve rates than alternatives.
\item \textbf{Simplicity is valued.} No coordinator agent needed; coordination emerges from shared state.
\item \textbf{Fault tolerance matters.} No single point of failure; agents can join/leave without protocol overhead.
\item \textbf{Pressure signals are available.} The domain provides measurable quality gradients.
\item \textbf{Problems are locally decomposable.} Local fixes improve global quality without cascading conflicts.
\end{enumerate}

\textbf{Hierarchical coordination may be appropriate when:}
\begin{enumerate}
\item \textbf{Explicit control is required.} Some domains require deterministic task assignment for regulatory or safety reasons.
\item \textbf{Interpretability is critical.} Hierarchical task assignment provides clear audit trails.
\item \textbf{Global planning is essential.} Tasks with strong non-local dependencies may benefit from centralized reasoning.
\end{enumerate}

\subsection{Band and Model Escalation as Adaptive Capability}

All experiments use a two-level escalation mechanism. \emph{Band escalation} cycles through sampling strategies (Exploitation $\to$ Balanced $\to$ Exploration, 7 ticks each) before \emph{model escalation} progresses through model sizes (0.5b $\to$ 1.5b $\to$ 3b parameters). Model escalation triggers when regions remain high-pressure for 21 consecutive ticks.

This mechanism proves beneficial for pressure-field: on hard problems, pressure-field achieves 15.6\% with escalation enabled. The escalation mechanism works because larger models have broader solution coverage and different sampling bands explore different regions of solution space.

\subsection{Future Work}

\begin{itemize}
\item \textbf{Learned pressure functions}: Current sensors are hand-designed. Can we learn pressure functions from solution traces?
\item \textbf{Adversarial robustness}: Can malicious agents exploit pressure gradients to degrade system performance?
\item \textbf{Multi-artifact coordination}: Extension to coupled artifacts where patches in one affect pressure in another
\item \textbf{Larger-scale experiments}: Testing on schedules with more rooms and longer time horizons to characterize scaling limits
\item \textbf{Alternative domains}: Applying pressure-field coordination to code refactoring, configuration management, and other artifact refinement tasks
\end{itemize}

\subsection{Societal Implications}

Pressure-field coordination raises societal concerns that extend beyond technical performance. We identify three critical issues---accountability attribution, metric gaming through Goodhart's Law, and explainability challenges---that require deliberate design choices in deployment.

\subsubsection{Accountability and Attribution}

When coordination emerges from shared pressure gradients rather than explicit delegation, attributing outcomes to individual agents becomes challenging. In hierarchical systems, task assignment creates clear accountability chains. In pressure-field coordination, multiple agents may contribute to a region through independent pressure-reducing actions, with no record of which agent ``owned'' the outcome.

This accountability diffusion has both benefits and risks. The benefit is fault tolerance: agent failures degrade performance gracefully rather than catastrophically. The risk is opacity in failure analysis: identifying which agent proposed a problematic patch---and what pressure signal motivated it---requires detailed logging that the minimal coordination mechanism does not inherently provide.

For deployment in regulated domains, this suggests an augmentation requirement: pressure-field systems must maintain audit logs recording patch provenance, pressure signals at proposal time, and validation outcomes. The coordination mechanism remains simple---agents coordinate through shared state---but operational deployment adds logging infrastructure preserving accountability.

\subsubsection{Goodhart's Law and Metric Gaming}

Goodhart's Law states: ``When a measure becomes a target, it ceases to be a good measure.'' Pressure-field coordination is vulnerable to this dynamic because agents are optimized to reduce pressure as defined by designer-specified functions. If those functions imperfectly capture true quality---and they inevitably do---agents will discover and exploit the mismatch.

Consider code quality pressure functions penalizing complexity metrics. An agent might reduce complexity by splitting functions excessively, harming readability while improving the metric. The mitigation is not abandoning pressure functions but designing them defensively: use multiple orthogonal pressure axes, include adversarial sensors detecting gaming strategies, and audit whether pressure reduction correlates with human quality judgments. Pressure functions should evolve as agents discover exploits.

Foundation models introduce second-order gaming concerns: \acp{llm} trained on internet-scale text may have implicit knowledge of how to game specific benchmarks. This suggests pressure functions for \ac{llm}-based systems should favor domain-specific quality signals harder to optimize without genuine improvement.

\subsubsection{Explainability Challenges}

In hierarchical systems, explanations follow delegation chains: ``Manager X assigned task Y to Worker Z because condition C held.'' In pressure-field coordination, the explanation is: ``Region R had high pressure, agent A proposed patch $\Delta$ reducing pressure by $\delta$.'' This is mechanistically transparent but causally opaque---it describes what happened without explaining why that particular patch was chosen.

This is the explainability trade-off inherent to emergent coordination: simplicity in mechanism comes at the cost of legibility in rationale. For many domains---code formatting, resource optimization, routine maintenance---the trade-off is acceptable: outcomes are verifiable even if reasoning is opaque. For high-stakes domains requiring human oversight, opacity is unacceptable.

The design implication is domain-dependent deployment: pressure-field coordination suits domains where outcome verification is cheap even if reasoning transparency is limited. For domains requiring justification to human stakeholders, hierarchical coordination remains necessary despite overhead costs.

\subsubsection{Design Implications}

These concerns suggest three requirements for responsible deployment: comprehensive audit logging preserving patch provenance and pressure signals, defensive pressure function design with multiple orthogonal axes, and domain-appropriate verification matching coordination opacity with outcome verifiability. The coordination mechanism remains simple---but responsible deployment requires surrounding infrastructure addressing accountability, gaming, and explainability.

%% ============================================================================
%% CONCLUSION
%% ============================================================================

\section{Conclusion}

We presented pressure-field coordination, a decentralized approach to multi-agent systems that achieves coordination through shared state and local pressure gradients rather than explicit orchestration.

Our theoretical analysis establishes convergence guarantees under pressure alignment conditions, with coordination overhead independent of agent count. Empirically, on meeting room scheduling across 1350 trials, we find:

\begin{enumerate}
\item \textbf{Pressure-field substantially outperforms all baselines} (48.5\% vs 12.6\% for conversation, 1.5\% for hierarchical, all $p < 0.001$). Implicit coordination through shared pressure gradients dramatically exceeds explicit hierarchical coordination.

\item \textbf{Pressure-field is the only strategy that scales to harder problems}. On medium and hard problems, pressure-field achieves 43.3\% and 15.6\% solve rates respectively, while all baselines achieve 0\%.

\item \textbf{Temporal decay is essential}. Disabling it reduces solve rate by 10 percentage points, trapping agents in local minima.
\end{enumerate}

The key contribution is demonstrating that implicit coordination can dramatically outperform explicit coordination for constraint satisfaction tasks. Pressure-field achieves this with simpler architecture: no coordinator agent, no explicit message passing, just shared state and local pressure gradients.

\Acp{fm} and stigmergic coordination exhibit natural synergy: \acp{fm}' zero-shot capabilities eliminate the need for domain-specific action representations, while pressure-field coordination eliminates the need for complex multi-agent protocols, together enabling simple yet highly effective multi-agent systems.

These results suggest that for domains with measurable quality signals and locally-decomposable structure, implicit coordination through shared state offers not just a simpler but a substantially more effective alternative to explicit hierarchical control.

%% ============================================================================
%% APPENDIX
%% ============================================================================

\appendix

\section{Experimental Protocol}

This appendix provides complete reproducibility information for all experiments.

\subsection{Hardware and Software}

\textbf{Hardware:} NVIDIA RTX 4070 8GB \ac{gpu}, AMD Ryzen 9 7940HS, 64GB RAM

\textbf{Software:}
\begin{itemize}
\item Rust 1.75+ (edition 2024)
\item Ollama (local \ac{llm} inference server)
\item Models: \texttt{qwen2.5:0.5b}, \texttt{qwen2.5:1.5b}, \texttt{qwen2.5:3b}
\end{itemize}

\subsection{Model Configuration}

Models are served via Ollama with a system prompt configured for schedule optimization:

\begin{lstlisting}
You optimize meeting room schedules. Given a schedule with gaps or conflicts,
propose ONE change: move, swap, or reschedule a meeting to reduce gaps,
overlaps, and utilization variance. Return ONLY your proposed change
in the format: MOVE meeting_id TO room day start_time
\end{lstlisting}

For multi-model setups (model escalation), models share a single Ollama instance with automatic routing based on model name.

\subsection{Sampling Diversity}

The experiment framework overrides default sampling parameters with three exploration bands per \ac{llm} call:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Band} & \textbf{Temperature} & \textbf{Top-p} \\
\midrule
Exploitation & 0.15--0.35 & 0.80--0.90 \\
Balanced & 0.35--0.55 & 0.85--0.95 \\
Exploration & 0.55--0.85 & 0.90--0.98 \\
\bottomrule
\end{tabular}
\caption{Sampling parameter ranges. Each \acs{llm} call randomly samples from one band.}
\label{tab:sampling}
\end{table}

This diversity prevents convergence to local optima and enables exploration of the solution space.

\subsection{Baseline Implementation Details}

To ensure fair comparison, all strategies use identical \ac{llm} prompts and parsing logic. The only differences are region selection and patch validation:

\textbf{Prompt (identical across all strategies):}
\begin{lstlisting}
You are a meeting room scheduler. Output schedules in the exact format requested.

Meeting Room Schedule Optimization.
Goal: Schedule meetings to minimize gaps and avoid conflicts.

Time Block: [time range]

Rooms:
  Room A: capacity 10
  Room B: capacity 8
  ...

Current assignments:
[current schedule for this time block]

Unscheduled meetings that could fit in this block:
  Meeting 5: 60min, 4 attendees
  Meeting 12: 30min, 2 attendees
  ...

Constraints:
- No attendee can be in multiple meetings at the same time
- Room capacity must fit attendees

Output the schedule for this time block.
\end{lstlisting}

\textbf{Region selection per strategy:}
\begin{itemize}
\item \textbf{Pressure-field}: Multiple agents select regions in parallel based on pressure gradients
\item \textbf{Hierarchical}: Always selects the single highest-pressure region
\item \textbf{Sequential}: Round-robin through regions in fixed order
\item \textbf{Random}: Uniform random region selection
\end{itemize}

\textbf{Patch validation per strategy:}
\begin{itemize}
\item \textbf{Pressure-field}: Validates all patches; applies only those reducing pressure
\item \textbf{Hierarchical}: Validates single patch; applies only if pressure reduces
\item \textbf{Sequential/Random}: No validation; applies any syntactically valid patch
\end{itemize}

\textbf{Why ``one patch per tick'' for hierarchical?} This asymmetry is inherent to the coordination paradigm, not an implementation choice. Hierarchical control requires the manager to: (1) observe global state, (2) select a target region, (3) delegate to a worker, (4) receive the proposed patch, and (5) validate before applying. Delegating to $K$ workers simultaneously would require additional coordination protocols---work distribution to avoid conflicts, result aggregation, tie-breaking when multiple patches target overlapping state---that would transform hierarchical control into a fundamentally different architecture. The sequential bottleneck is the cost of centralized decision-making. Pressure-field avoids this overhead through stigmergic coordination: agents observe shared state independently and propose patches without central delegation, enabling natural parallelism.

\subsection{Problem Generation and Seeding}

Fair strategy comparison requires identical problem instances: each strategy must face the same scheduling challenge within a trial. We achieve this through deterministic seeding.

Each trial generates its problem from a seed:
\[
\text{seed} = \text{trial} \times 1000 + \text{agent\_count}
\]

Trial 5 with 2 agents yields seed 5002, producing identical meeting configurations whether evaluated with pressure-field, conversation, or hierarchical coordination.

The seed governs all stochastic generation:
\begin{itemize}
\item Meeting durations (1--4 time slots)
\item Attendee assignments (2--5 participants)
\item Room preferences and capacity requirements
\item Pre-scheduled vs.\ unassigned meeting distribution
\item Time slot availability patterns
\end{itemize}

\subsection{Experiment Commands}

\textbf{Main Grid (Strategy Comparison):}
\begin{lstlisting}
schedule-experiment --host http://localhost:11434 \
  grid --trials 30 \
  --strategies pressure_field,sequential,random,hierarchical,conversation \
  --agents 1,2,4 --difficulties easy,medium,hard \
  --max-ticks 50
\end{lstlisting}

\textbf{Ablation Study:}
\begin{lstlisting}
schedule-experiment --host http://localhost:11434 \
  ablation --trials 30 --agents 2 --difficulty easy --max-ticks 50
\end{lstlisting}

\textbf{Scaling Analysis:}
\begin{lstlisting}
schedule-experiment --host http://localhost:11434 \
  grid --trials 30 \
  --strategies pressure_field \
  --agents 1,2,4 --difficulties easy \
  --max-ticks 50
\end{lstlisting}

\textbf{Band and Model Escalation:}
\begin{lstlisting}
# Full escalation chain enabled by default
# Band escalation: Exploitation -> Balanced -> Exploration (7 ticks each)
# Model escalation: 0.5b -> 1.5b -> 3b (after 21 ticks at high pressure)
schedule-experiment --host http://localhost:11434 \
  grid --trials 30 --agents 2 --difficulties medium \
  --max-ticks 100
\end{lstlisting}

\textbf{Difficulty Scaling:}
\begin{lstlisting}
# Easy: 3 rooms, 20 meetings, 70% pre-scheduled
schedule-experiment --host http://localhost:11434 \
  grid --trials 30 --agents 2 --difficulties easy --max-ticks 50

# Medium: 5 rooms, 40 meetings, 50% pre-scheduled
schedule-experiment --host http://localhost:11434 \
  grid --trials 30 --agents 2 --difficulties medium --max-ticks 50

# Hard: 5 rooms, 60 meetings, 30% pre-scheduled
schedule-experiment --host http://localhost:11434 \
  grid --trials 30 --agents 2 --difficulties hard --max-ticks 100
\end{lstlisting}

\subsection{Metrics Collected}

Each experiment records:
\begin{itemize}
\item \texttt{solved}: Boolean indicating all meetings scheduled with zero overlaps
\item \texttt{total\_ticks}: Iterations to solve (or max if unsolved)
\item \texttt{pressure\_history}: Pressure value at each tick (gaps + overlaps + util\_var + unscheduled)
\item \texttt{band\_escalation\_events}: Sampling band changes (tick, from\_band, to\_band)
\item \texttt{model\_escalation\_events}: Model tier changes (tick, from\_model, to\_model)
\item \texttt{final\_model}: Which model tier solved the schedule
\item \texttt{token\_usage}: Prompt and completion tokens consumed
\end{itemize}

\subsection{Replication Notes}

Each configuration runs 30 independent trials with different random seeds to ensure reliability. Results report mean solve rates and tick counts across trials.

\subsection{Estimated Runtime}

\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Experiment} & \textbf{Configurations} & \textbf{Trials} & \textbf{Est.\ Time} \\
\midrule
Main Grid & 45 & 30 & 5 hours \\
Ablation & 5 & 30 & 1 hour \\
Scaling & 3 & 30 & 45 min \\
Difficulty & 15 & 30 & 2.5 hours \\
\midrule
\textbf{Total} & & & \textbf{$\sim$9 hours} \\
\bottomrule
\end{tabular}
\caption{Estimated runtime for all experiments on NVIDIA RTX 4070 8GB \acs{gpu}.}
\label{tab:runtime}
\end{table}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
